{
    "Tracking and Recognition":
    [
        {
            "title": "ObjectRecognition",
            "text": "The capability to identify the form and shape of an object and their position in space using a camera and computer vision technique. Object Recognition is able to tell what the object is based on deep learning and machine learning algorithms.\nMore specifically, Object Recognition can be broken down to three levels: Object detection, recognition and tracking."
        },
        {
            "title": "Room/SceneRecognition",
            "text": "The capability to understand the world around you so that AR experiences are more immersive by adding augmented objects to the world in accurate positions. This capability combines recognition of notable scene features with motion sensing data to recognize larger structures than table-size objects, rooms, faces of buildings, courtyards and etc. It works best with predictable lighting conditions."
        },
        {
            "title": "ExtendedTracking",
            "text": "The capability to keep digital augmentations that are attached to a targeted object, scene, or image to stay in the FOV even when the initial target is no longer in the field of view or cannot be directly tracked for other reasons. Therefore, AR experiences feel more fluid and immersive."
        },
        {
            "title": "6DoF",
            "text": "6DoF (6 Degrees of Freedom of movement in 3D space) refers to both translation and rotation about x,y and z axes (yaw, pitch, roll). In addition to the accelerometer and gyroscope, 6DoF requires camera(s) or external sensors in order for it to work accurately. "
        },
        {
            "title": "3DoF",
            "text": "3DoF (3 Degrees of Freedom of movement in 3D space) refers to rotation(yaw, pitch,roll) about x,y and z axes. It  lacks the other three movements of  translation. However, there are hardware add-ons to enable a 3DoF equipment to do 6DoF."
        },
        {
            "title": "MarkerTracking",
            "text": "The capability to recognize and track specific images through cameras and superimpose virtual content onto them. These images sometimes are referred to fiducial markers (AR markers). Using computer vision techniques of contour detection, feature extraction and pose estimation, the AR hardware processes the data of image position, size and orientation from the markers for building virtual content."
        },
        {
            "title": "PlaneDetection",
            "text": "Plane Tracking, or marker-less tracking, uses objects in the image frame instead of an AR marker in addition to the standard computer vision techniques. For example, AKAZE or ORB from OpenCV is used to compare local features and to find matches between video frames. Compared to marker tracking, Plane Tracking requires good lighting, not as robust, and has higher computation cost."
        },
        {
            "title": "FacialRecognition",
            "text": "Facial Recognition identifies or verifies a person, which generally works by creating a template of the target\u2019s facial image and comparing the template to preexisted photos of faces. The template is created by use of measurements, distance between eye, width of nose, length of jaw line. Moreover, it can work by extracting landmarks such as a nose or eyes. In general, there are two approaches, geometric (shapes) or photometric (pixels). 3D facial recognition is not affected by lighting. Common applications include photo tagging, security, social media filters, and etc. One note is that for biometrics, it is less accurate than iris or fingerprint recognition."
        },
        {
            "title": "GPS",
            "text": "For software, location-based tracking means being able to anchor a virtual object onto the real world by longitude and latitude data. Global Positioning System (GPS) is a satellite-based radionavigation system and  provides geolocation and time information anywhere on or near the Earth where there is an unobstructed line of sight to four or more gps satellites (31 in orbit). The accuracy depends on weather, line of sight to satellites, number of channels on receiver."
        },
        {
            "title": "DepthSensing",
            "text": "The capability to  understand which objects are closer than others. Two common approaches. Method 1: Depth sensor uses an infrared projector that measures the time it takes for the infrared light to reflect off objects. Method 2: two camera lenses to compare two images to capture the depth of objects in stereo, like how human eyes do."
        },
        {
            "title": "LightEstimation",
            "text": "The capability to detect the lighting data of the user\u2019s environment. Some AR features need lighting data for better performance and/or user-experiences. For example, it can be used to adjust intensity and colors of the virtual content to be more visible."
        },
        {
            "title": "LightProjection",
            "text": "Project-based AR directly overlays digital projection onto the physical world, which can create an immersive and shared AR experience. It typically works on projectors with depth cameras. For some, users are able to touch and interact with virtual content."
        },
        {
            "title": "VoiceRecognition",
            "text": "The capability to recognize humans\u2019 speeches. Voice recognition is commonly used to perform commands on a device or multiple connected devices so that users don\u2019t have to use a mouse, keyboarch or press any buttons. Use cases include voice dialing, domotic appliance control in smart homes, and etc."
        },
        {
            "title": "Body Recognition",
            "text": "The capability to recognize whether there's a body in the scene/environment. Some are able to do body segmentation by narrowing down body parts to joints and connections. Potential applications include detecting human presence, body and movement tracking, and etc."
        },
        {
            "title": "Cylinder/conical surface detection and tracking (software)",
            "text": "Able to place AR content onto curved surfaces such as soda cans, in addition to planes, flat markers and images."
        },
        {
            "title": "Motion Capture",
            "text": ""
        },
        {
            "title": "people occlusion",
            "text": ""
        },
        {
            "title": "Multi-object tracking",
            "text": ""
        }
    ],
    "Display of Information":
    [
        {
            "title": "PictureTaking",
            "text": "The capability to take a screenshot of what the user is seeing.\nSome devices are able to capture the virtual image along the real for combined AR results.\n"
        },
        {
            "title": "VideoRecording",
            "text": "The capability to record a video and audio of what the user is seeing. Some devices are able to capture the virtual content superimposed on the real world."
        },
        {
            "title": "Communication_VideoStreaming",
            "text": "The capability to stream what the user is seeing or the camera is pointed to so that multiple users can operate on the shared data in real time."
        },
        {
            "title": "Communication_Calling",
            "text": "The capability to call or communicate to another user through audio."
        },
        {
            "title": "Communication_Telepresence",
            "text": "Telepresence refers to a set of technologies which allow a person to feel as if they were present, to give the appearance of being present, or to have an effect. One approach is to capture a person\u2019s appearance and body movements and present a hologram of them to the other connected device in real time, as if the person is present in another user\u2019s context."
        },
        {
            "title": "Non-native",
            "text": "Non-native means the AR content can be running on several platforms like mobile phones, computers, and laptops by sharing via a URL web link. Users do not have to download any native apps to their devices."
        },
        {
            "title": "Cross-platform \n(for hardware) -> Computing units compatibility?",
            "text": "A majority of AR glasses require a standalone computing unit to run and process data. The capability of Hardware cross-platform means whether the AR glasses (or other devices) can be run on different computing units, like iphones, android phones, PC and etc."
        },
        {
            "title": "Cloud/SpatialAnchor",
            "text": "By sharing virtual content to the cloud and anchoring it to a shared physical space, multiple users can view and interact the virtual content from different positions simultaneously in real time."
        },
        {
            "title": "Show2DContent",
            "text": "Able to visualize 2D contents such as texts, images, and/or videos"
        },
        {
            "title": "Show3DContent",
            "text": "Able to visualize 3D contents such as 3D models and animations"
        }
    ],
    "Augmentation and Interaction":
    [
        {
            "title": "HandTracking",
            "text": "The capability to recognize hands\u2019 movements and/or gestures. Hands can be used to interact with menus, models, and the environment. For example, it can be used to practice hands-on activities for education and training, such as surgeons and mechanics. (Current hand tracking is accurate but not from all angles/all situations)"
        },
        {
            "title": "EyeTracking",
            "text": "The capability to track where a person\u2019s gaze is directed by using human-facing sensors. Applications include: detecting a person\u2019s presence, attention, and focus, eye-controlled UI, and rendering optimization. Note: many AR hardwares do not have eye-tracking on but one can use add-ons, such as Pupil Core Binocular."
        },
        {
            "title": "HandController",
            "text": "A piece of hardware that users can interact with hands to operate a device. This includes touchpads, which support familiar swipes and tap gestures to operate a device. Some AR equipment are using phones as a controller while functioning as a computer unit to the equipment."
        }
    ]
}